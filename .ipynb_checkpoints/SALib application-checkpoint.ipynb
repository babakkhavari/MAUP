{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1d1232b",
   "metadata": {},
   "source": [
    "# SALib application\n",
    "\n",
    "The following notebook can be used in order to replicate the SALib application developed for **The modifiable areal unit problem in geospatial least-cost electrification modelling** with the DBSCAN algorithm. Please refer **ADD LINK TO MENDELEY** for the final input files used in the analysis. \n",
    "\n",
    "The code generates sensitivity measures for given input parameters with regards to a specific output parameter.\n",
    "\n",
    "## Theory\n",
    "\n",
    "SALib<sup>1</sup> is an open-source python library containing applications of some of the most common sensitivity analysis methods. For our publication we have used the Delta Moment-Independent Measure (DMIM)<sup>2, 3</sup>. \n",
    "\n",
    "## Input\n",
    "\n",
    "A \"summary of summaries\" file is needed. For the paper a summary file was generated using the summary files zipped in the **Results_used_in_Salib** folder (the finished input file is also available on this repo at: ).\n",
    "\n",
    "The summary files includes:<br>\n",
    "* 6,240 rows representing three countries <br> \n",
    "* Column C through P are model inputs <br>\n",
    "* Column Q through AF are model outputs <br>\n",
    "* Each country has three specific values that effect our model and are usually not subject to sensitivity analysis (current electrification rate, population in 2030 and national population density). They are the same across all national scenarios (2,080 entries per value). These values are taken from literature and considered \"known\", but when comparing all three countries they have a certain effect and are therefore included. **Note** these values are not in the file and added in the cells below. <br>\n",
    "\n",
    "## Pre-processing\n",
    "\n",
    "If you wish to conduct the sensitivity analysis on your own data you need to first generate the population layers (please refer to the DBSCAN.ipynb for information on how to do so). You also need to run OnSSET for the desired scenarios. Information on how to run OnSSET can be found on the official OnSSET websites and the various resources linked there (http://www.onsset.org/). The OnSSET codes used for this work specifically differs from the official OnSSET codes currently available throught the OnSSET repository, the codes for the paper are available in this repository with documentation of what has changed. \n",
    "\n",
    "## Output\n",
    "The output includes:\n",
    "\n",
    "* **delta** - DMIM delta value for each input \n",
    "* **S1** - First order Sobol index for each input\n",
    "* **delta_conf** - The confidence intervall for each input's DMIM delta value\n",
    "* **S1_conf** - The confidence intervall for each input's first order Sobol index\n",
    "____________________________________________________________________________________________________________________________\n",
    "<sup>1</sup> Herman, J. & Usher, W. SALib: An open-source Python library for Sensitivity Analysis. Journal of Open Source Software 2, 97 (2017). <br>\n",
    "<sup>2</sup> Borgonovo, E. (2007). “A new uncertainty importance measure.” Reliability Engineering & System Safety, 92(6):771-784, doi:10.1016/j.ress.2006.04.015. <br>\n",
    "<sup>3</sup> Plischke, E., E. Borgonovo, and C. L. Smith (2013). “Global sensitivity measures from given data.” European Journal of Operational Research, 226(3):536-550, doi:10.1016/j.ejor.2012.11.047. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d30b83",
   "metadata": {},
   "source": [
    "## Cell 1 - Importing packages\n",
    "**Do not edit this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from SALib.analyze import delta\n",
    "from SALib.util import read_param_file\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40971636",
   "metadata": {},
   "source": [
    "## Cell 2 - Preprocessing\n",
    "\n",
    "Please note that this section has to be ran and is highly specific to country and input data. \n",
    "\n",
    "Here we add: <br>\n",
    "* The electrification rate in the start year for the countries studied (by the iso-2 code included in the summary file)<br>\n",
    "* The population in the end year (2030) by the iso-2 code<br>\n",
    "\n",
    "The values entered here may have to be updated if the country is changed or new data becomes available.\n",
    "\n",
    "After the new columns have been generated the columns are rearranged in order to have all the inputs first and all the outputs last. The dataframe is also shuffled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7de4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"summaries_round_2.csv\", sep=';')\n",
    "\n",
    "df['ElecRate'] = 0.42\n",
    "df[\"Pop2030\"] = 15672000\n",
    "\n",
    "df['ElecRate'] = np.where(df['Country'] == 'na', 0.54, df['ElecRate'])\n",
    "df['ElecRate'] = np.where(df['Country'] == 'mw', 0.18, df['ElecRate'])\n",
    "\n",
    "df['Pop2030'] = np.where(df['Country'] == 'na', 3010873, df['Pop2030'] )\n",
    "df['Pop2030'] = np.where(df['Country'] == 'mw', 24849000, df['Pop2030'])\n",
    "\n",
    "cols = ['EDemand',\n",
    " 'GridGenCost',\n",
    " 'PVCost',\n",
    " 'GridCapInvCost',\n",
    " 'DiscountRate',\n",
    " 'LVCost',\n",
    " 'MVCost',\n",
    " 'GridLosses',\n",
    " 'Core',\n",
    " 'Buffer',\n",
    " 'Admin',\n",
    " 'Method',\n",
    " 'Res',\n",
    " 'ElecRate',\n",
    " 'NatPopDens',\n",
    " 'Pop2030',\n",
    " 'PopGrid',\n",
    " 'PopMG',\n",
    " 'PopSA',\n",
    " 'AddedCapGrid',\n",
    " 'AddedCapSA',\n",
    " 'AddedCapMG',\n",
    " 'GridInv',\n",
    " 'SAInv',\n",
    " 'MGInv',\n",
    " 'TotInv',\n",
    " 'Country']\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "df[\"RatioGridPop\"] = 100*(df[\"PopGrid\"]/df['Pop2030'])\n",
    "df[\"RatioMGPop\"] = 100*(df[\"PopMG\"]/df['Pop2030'])\n",
    "df[\"RatioSAPop\"] = 100*(df[\"PopSA\"]/df['Pop2030'])\n",
    "\n",
    "df[\"RatioGridInv\"] = 100*(df[\"GridInv\"]/df['TotInv'])\n",
    "df[\"RatioSAInv\"] = 100*(df[\"SAInv\"]/df['TotInv'])\n",
    "df[\"RatioMGInv\"] = 100*(df[\"MGInv\"]/df['TotInv'])\n",
    "\n",
    "df_shuffled = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e7331",
   "metadata": {},
   "source": [
    "## Cell 3 - Splitting the file into national versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39831554",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfB = df_shuffled.loc[df['Country'] == 'bj']\n",
    "dfN = df_shuffled.loc[df['Country'] == 'na']\n",
    "dfM = df_shuffled.loc[df['Country'] == 'mw']\n",
    "dfB['id'] = np.arange(len(dfB))\n",
    "dfN['id'] = np.arange(len(dfN))\n",
    "dfM['id'] = np.arange(len(dfM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b6ca6",
   "metadata": {},
   "source": [
    "## Cell 4 - Reading param files\n",
    "SALib requires a parameter file. \n",
    "\n",
    "The parameter files are provided in the **Sample input** folder. The files have to include one row for each input paramter and three columns: 1) name of input, 2) minimum value and 3) maximum value\n",
    "\n",
    "If you use your own data these have to be generated from scratch. \n",
    "\n",
    "We are reading four parameter files 1) one for the merged data, 2) one for Benin, 3) one for Namibia and 4) one for Malawi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c9181d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'params_merged.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7df2aa1d5329>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mproblem_merged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_param_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params_merged.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mproblem_bj\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mread_param_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params_ben.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mproblem_na\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_param_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params_nam.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mproblem_mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_param_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params_mal.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\MAUP\\lib\\site-packages\\SALib\\util\\__init__.py\u001b[0m in \u001b[0;36mread_param_file\u001b[1;34m(filename, delimiter)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0mfieldnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lower_bound'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'upper_bound'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'group'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dist'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSniffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msniff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mcsvfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'params_merged.txt'"
     ]
    }
   ],
   "source": [
    "problem_merged = read_param_file('params_merged.txt')\n",
    "problem_bj =read_param_file('params_ben.txt')\n",
    "problem_na = read_param_file('params_nam.txt')\n",
    "problem_mw = read_param_file('params_mal.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142f091",
   "metadata": {},
   "source": [
    "## Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_values=df_shuffled.iloc[:, : 16]\n",
    "np.savetxt(r'model_input_merged.txt', param_values.values)\n",
    "X_merged = np.loadtxt(r\"model_input_merged.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df_shuffled[\"RatioMGPop\"]\n",
    "np.savetxt(r'model_output_merged.txt', out.values)\n",
    "Y_merged = np.loadtxt(r\"model_output_merged.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1fea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_merged = delta.analyze(problem_merged, X_merged, Y_merged, num_resamples=10, conf_level=0.95, print_to_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e18b0",
   "metadata": {},
   "source": [
    "## Benin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_values=dfB.iloc[:, : 14]\n",
    "np.savetxt(r'model_input_ben.txt', param_values.values)\n",
    "X_bj = np.loadtxt(r\"model_input_ben.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dfB[\"RatioMGPop\"]\n",
    "np.savetxt(r'model_output_ben.txt', out.values)\n",
    "Y_bj = np.loadtxt(r\"model_output_ben.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70351fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Si_ben = delta.analyze(problem_bj, X_bj, Y_bj, num_resamples=10, conf_level=0.95, print_to_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7258d21e",
   "metadata": {},
   "source": [
    "## Malawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1fa895",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_values=dfM.iloc[:, : 14]\n",
    "np.savetxt(r'model_input_mal.txt', param_values.values)\n",
    "X_mw = np.loadtxt(r\"model_input_mal.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dfM[\"LCOE\"]\n",
    "np.savetxt(r'model_output_mal.txt', out.values)\n",
    "Y_mw = np.loadtxt(r\"model_output_mal.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Si_mal = delta.analyze(problem_mw, X_mw, Y_mw, num_resamples=10, conf_level=0.95, print_to_console=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037051f",
   "metadata": {},
   "source": [
    "## Namibia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_values=dfN.iloc[:, : 14]\n",
    "np.savetxt(r'model_input_nam.txt', param_values.values)\n",
    "X_na = np.loadtxt(r\"model_input_nam.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dfN[\"LCOE\"]\n",
    "np.savetxt(r'model_output_nam.txt', out.values)\n",
    "Y_na = np.loadtxt(r\"model_output_nam.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Si_nam = delta.analyze(problem_na, X_na, Y_na, num_resamples=10, conf_level=0.95, print_to_console=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
